## Elastic Dump in Docker

```bash
docker run --rm -ti elasticdump/elasticsearch-dump \
	--input=http://<user>:<password>@34.69.228.174:419/logs \  
	--output=https://<user>:<password>@elastic.carti3r.tk/logs \  
	--type=data
```

### Docker install

If you prefer using docker to use elasticdump, you can download this project from docker hub:

```bash
docker pull elasticdump/elasticsearch-dump
```

Then you can use it just by :

- using `docker run --rm -ti elasticdump/elasticsearch-dump`
- you'll need to mount your file storage dir `-v <your dumps dir>:<your mount point>` to your docker container

Example:

```bash
# Copy an index from production to staging with mappings:
docker run --rm -ti elasticdump/elasticsearch-dump \
  --input=http://production.es.com:9200/my_index \
  --output=http://staging.es.com:9200/my_index \
  --type=mapping
docker run --rm -ti elasticdump/elasticsearch-dump \
  --input=http://production.es.com:9200/my_index \
  --output=http://staging.es.com:9200/my_index \
  --type=data

# Backup index data to a file:
docker run --rm -ti -v /data:/tmp elasticdump/elasticsearch-dump \
  --input=http://production.es.com:9200/my_index \
  --output=/tmp/my_index_mapping.json \
  --type=data
```

If you need to run using `localhost` as your ES host:

```bash
docker run --net=host --rm -ti elasticdump/elasticsearch-dump \
  --input=http://staging.es.com:9200/my_index \
  --output=http://localhost:9200/my_index \
  --type=data
```

## Dump Format

The file format generated by this tool is line-delimited JSON files. The dump file itself is not valid JSON, but each line is. We do this so that dumpfiles can be streamed and appended without worrying about whole-file parser integrity.

For example, if you wanted to parse every line, you could do:

```
while read LINE; do jsonlint-py "${LINE}" ; done < dump.data.json
```

